<!DOCTYPE html>
<html>
<head>
   <title>Introduction &gt; Platform Architectures &gt; Alpha on ASA-EmulatR &gt; Virtual Address Space — Overview &gt; Memory Management &gt; Caching &gt; Caching-Code</title>
   <meta name="viewport" content="width=device-width, initial-scale=1">
   <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />   
   <meta http-equiv="X-UA-Compatible" content="IE=edge" />
   <meta name="generator" content="Help &amp; Manual" />
   <meta name="keywords" content="" />
   <meta name="description" content="/* ALPHA AXP CACHE ARCHITECTURE ANALYSIS ===================================== &nbsp;ACTUAL ALPHA CACHE HIERARCHY: CPU Pipeline: ├── L1 I-Cache (Instruction Fetch) - 8KB-64KB, ded" />
   <link type="text/css" href="default.css" rel="stylesheet" />
   <link type="text/css" href="custom.css" rel="stylesheet" />

   <style TYPE="text/css" media="screen"> 
      html, body { margin:0; 
        padding:0; 
        background: #ffffff; 
      } 
      div#printheader { display: none; }
      #idheader { 
        width:100%; 
        min-height: 60px; 
        padding: 0; 
        margin: 0;
        position: fixed;
        top: 0;
        background: #2C5D88;
        z-index: 2;
      } 
      /* The "min-height" for "#idheader table" ensures that the (blue) header of the topic
         has at least the same height as the header of the navigation panel left of it */
      #idheader table { min-height: 59px;}             
      #idheader h1 span { color: #FFF }     
      #idnav {
        text-align: right;
        width: 126px;
        vertical-align: middle;        
      } 
      #idnav a { text-decoration: none }
      #idnav span {
        display: inline-block;
        width: 24px;
        height: 24px;
        margin-left: 4px;
        background:url('hm_webhelp_buttons_grey.png') top left no-repeat;
      } 
      #idnav a span {
        background-image:url('hm_webhelp_buttons_white.png');
      } 
      #idnav a span:hover {
        background-image:url('hm_webhelp_buttons_orange.png');
      } 
      #idnav span.hmbtnprev { background-position: 0 -32px }
      #idnav span.hmbtnnext { background-position: -24px -32px }
      #idnav span.hmbtntop  { background-position: -48px -32px }
      #idnav span.hmbtntoggle  { width: 20px; background-position: -70px -32px }
      #idnav span.hmbtnprint  { background-position: -88px -32px }

      #callout-table, #overview-table {display:block; position:relative; top:0; left:0;}
      #callout-icon {display:block; position:absolute; top:-11px; left:-11px;}
      #callout-icon-flag {display:block; position:absolute; top:-11px; left:-8px;}
      #callout-table a {text-decoration: none; color: blue;}
      #callout-table a:visited {text-decoration: none; color: blue;}
      #overview-table a {text-decoration: none; color: black;}
      #overview-table a:visited {text-decoration: none; color: black;}
      #callout-table a:hover, #overview-table a:hover {text-decoration: underline;}       
      p.help-url { margin: 20px 0 5px 0; text-align: center; }
	  p.help-url a:link { font-size: 50%; text-decoration: none; color: black; }
	  p.help-url a:visited { color: black; }
	  p.help-url a:hover { font-size: 95%; text-decoration: underline; }
      #switchtoggles { text-align: right; padding: 0 2px 0 0; font-size: 90%; } 
      .sync-toc { color: #FFF; font-size: 8pt; font-weight: bold; display: none; }
      .sync-toc a { color: #FFF; text-decoration: none; font-weight: bold;}
      .sync-toc a:visited { color: #FFF; }
      .sync-toc a:hover { text-decoration: underline; }
	  a#printbuttonlink { cursor: pointer; }
      a.hmanchor { display: inline-block; margin-top: -4em; padding-top: 4em; }  
   </style>
   <style TYPE="text/css" media="print">
      div#idheader, img.dropdown-toggle-icon, p.help-url { display:none } 
   </style>
   
   <script type="text/javascript" src="jquery.js"></script>
   <script type="text/javascript" src="helpman_settings.js"></script>
   <script type="text/javascript" src="helpman_topicinit.js"></script>

   <script type="text/javascript">
     HMSyncTOC("index.html", "caching-code.html");
   </script>
   <script type="text/javascript" src="highlight.js"></script>
   <script type="text/javascript">
     $(document).ready(function(){highlight();});
   </script>
</head>
<body>


<div id="printheader"><h1 class="p_Heading1" style="page-break-after: avoid;"><span class="f_Heading1">Caching-Code</span></h1>
</div>
<div id="idheader">
<div id="idheaderbg">
<table style="width:100%;border:none;margin:0px;" cellspacing="0" cellpadding="0"> 
  <tr>
    <td class="topichead" style="text-align:left; vertical-align:middle">
      <p class="sync-toc">&lt;&lt; <a rel="nofollow" href="index.html?caching-code.html" target="_top">Click to Display Table of Contents</a> &gt;&gt;</p>
      <p class="crumbs"><b>Navigation:</b>&nbsp;
      
      <a href="introduction.html">Introduction</a> &gt; Platform Architectures &gt; <a href="architecture.html">Alpha on ASA-EmulatR</a> &gt; <a href="virtualization-address-space.html">Virtual Address Space — Overview</a> &gt; <a href="memory-management.html">Memory Management</a> &gt; <a href="caching---instruction.html">Caching</a>&nbsp;&gt;</p>
   
      <h1 class="p_Heading1" style="page-break-after: avoid;"><span class="f_Heading1">Caching-Code</span></h1>

    </td>
    <td class="topichead" id="idnav">
      
      <a href="alphainstructioncache.html" title="Previous Topic"><span class="hmbtnprev"></span></a>
      <a href="caching---instruction.html" title="Parent Chapter"><span class="hmbtntop"></span></a>
      <a href="code-3.html" title="Next Topic"><span class="hmbtnnext"></span></a>
      
    </td>
  </tr>  
</table>
</div>
</div>  

<div id="idcontent"><div id="innerdiv">
<!-- Ask Internet Explorer 6.users to update their obsolete and dangerous browser --> 
<!--[if lt IE 7]><div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;'><a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode"><img src="http://storage.ie6countdown.com/assets/100/images/banners/warning_bar_0000_us.jpg" border="0" height="42" width="820" alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today." /></a></div><![endif]-->

<!--ZOOMRESTART-->
<p class="p_Normal">/*</p>
<p class="p_Normal">ALPHA AXP CACHE ARCHITECTURE ANALYSIS</p>
<p class="p_Normal">=====================================</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">ACTUAL ALPHA CACHE HIERARCHY:</p>
<p class="p_Normal">CPU Pipeline:</p>
<p class="p_Normal">├── L1 I-Cache (Instruction Fetch) - 8KB-64KB, dedicated to fetch unit</p>
<p class="p_Normal">├── L2 D-Cache (Data Execute) - 256KB-4MB, dedicated to execution units &nbsp;</p>
<p class="p_Normal">└── L3 Unified Cache (SMP Coherency) - 2MB-64MB, shared across CPUs</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">WHY THIS SEPARATION EXISTS AND PERFORMANCE BENEFITS:</p>
<p class="p_Normal">*/</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal"><span style="font-weight: bold;">// 1. FETCH vs EXECUTE BANDWIDTH REQUIREMENTS</span></p>
<p class="p_Normal">class AlphaCacheArchitecture {</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp;FETCH CHARACTERISTICS:</p>
<p class="p_Normal"> &nbsp; &nbsp;- Sequential access patterns (PC, PC+4, PC+8...)</p>
<p class="p_Normal"> &nbsp; &nbsp;- High bandwidth requirements (4-6 instructions per cycle)</p>
<p class="p_Normal"> &nbsp; &nbsp;- Predictable prefetch opportunities</p>
<p class="p_Normal"> &nbsp; &nbsp;- Read-only (instructions never written during execution)</p>
<p class="p_Normal"> &nbsp; &nbsp;- Small working set per function</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;EXECUTE CHARACTERISTICS: &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;- Random access patterns (data structures, arrays, stacks)</p>
<p class="p_Normal"> &nbsp; &nbsp;- Variable size accesses (1, 2, 4, 8 bytes)</p>
<p class="p_Normal"> &nbsp; &nbsp;- Read/write mix with complex coherency needs</p>
<p class="p_Normal"> &nbsp; &nbsp;- Large working sets spanning multiple data structures</p>
<p class="p_Normal"> &nbsp; &nbsp;- Cache line sharing between CPUs</p>
<p class="p_Normal"> &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// L1 I-Cache optimized for instruction fetch</p>
<p class="p_Normal"> &nbsp; &nbsp;struct L1InstructionCache {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int SIZE = 64 * 1024; &nbsp; &nbsp; &nbsp;// 64KB</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int LINE_SIZE = 32; &nbsp; &nbsp; &nbsp; &nbsp;// 32-byte lines (8 instructions)</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int ASSOCIATIVITY = 2; &nbsp; &nbsp; // 2-way set associative</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int LATENCY = 1; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // 1 cycle hit time</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Optimizations:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Small line size for minimal transfer on miss</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Sequential prefetch logic built-in</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Branch prediction integration</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - No write logic needed (read-only)</p>
<p class="p_Normal"> &nbsp; &nbsp;};</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// L2 D-Cache optimized for data execution</p>
<p class="p_Normal"> &nbsp; &nbsp;struct L2DataCache {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int SIZE = 2 * 1024 * 1024; // 2MB</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int LINE_SIZE = 64; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 64-byte lines</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int ASSOCIATIVITY = 4; &nbsp; &nbsp; &nbsp; // 4-way set associative</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int LATENCY = 12; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 12 cycles hit time</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Optimizations:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Large lines for spatial locality</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Write-back with victim cache</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Load/store queue integration</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Banking for multiple ports</p>
<p class="p_Normal"> &nbsp; &nbsp;};</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// L3 Unified Cache for SMP coherency</p>
<p class="p_Normal"> &nbsp; &nbsp;struct L3UnifiedCache {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int SIZE = 16 * 1024 * 1024; // 16MB shared</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int LINE_SIZE = 128; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 128-byte lines</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int ASSOCIATIVITY = 8; &nbsp; &nbsp; &nbsp; &nbsp;// 8-way set associative</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;static constexpr int LATENCY = 35; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // 35 cycles hit time</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Optimizations:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Directory-based coherency protocol</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Inclusive of L1/L2 for simpler coherency</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Multiple CPU ports</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// - Advanced replacement algorithms</p>
<p class="p_Normal"> &nbsp; &nbsp;};</p>
<p class="p_Normal">};</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal"><span style="font-weight: bold;">// 2. PIPELINE BANDWIDTH ANALYSIS</span></p>
<p class="p_Normal">class AlphaPipelinePerformance {</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp;ALPHA 21264 PIPELINE (6-wide superscalar):</p>
<p class="p_Normal"> &nbsp; &nbsp;- Fetch: Up to 4 instructions per cycle</p>
<p class="p_Normal"> &nbsp; &nbsp;- Decode: Up to 4 instructions per cycle &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;- Execute: Up to 6 operations per cycle</p>
<p class="p_Normal"> &nbsp; &nbsp;- Retire: Up to 11 instructions per cycle</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;CACHE BANDWIDTH REQUIREMENTS:</p>
<p class="p_Normal"> &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;void analyzeBandwidthNeeds() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// INSTRUCTION FETCH BANDWIDTH</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;const int FETCH_WIDTH = 4; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // 4 instructions per cycle</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;const int INSTRUCTION_SIZE = 4; &nbsp; &nbsp; &nbsp;// 4 bytes per instruction</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;const int FETCH_BANDWIDTH = FETCH_WIDTH * INSTRUCTION_SIZE; // 16 bytes/cycle</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// DATA EXECUTE BANDWIDTH &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;const int LOAD_UNITS = 2; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 2 load units</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;const int STORE_UNITS = 1; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // 1 store unit</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;const int MAX_DATA_SIZE = 8; &nbsp; &nbsp; &nbsp; &nbsp; // 8-byte loads/stores</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;const int DATA_BANDWIDTH = (LOAD_UNITS + STORE_UNITS) * MAX_DATA_SIZE; // 24 bytes/cycle</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;PERFORMANCE PROBLEM WITH UNIFIED L1:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;Total bandwidth needed: 16 + 24 = 40 bytes/cycle</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;Typical unified cache bandwidth: 16-32 bytes/cycle</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;Result: Pipeline stalls due to cache port conflicts</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"><span style="font-weight: bold;"> &nbsp; &nbsp;// 3. ACCESS PATTERN CONFLICTS</span></p>
<p class="p_Normal"> &nbsp; &nbsp;void analyzeAccessPatterns() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;INSTRUCTION ACCESS PATTERNS:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Sequential: PC, PC+4, PC+8, PC+12</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Branches: Jump to new sequential stream</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Loops: Repeated access to same instruction range</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Calls: Stack-based locality</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;DATA ACCESS PATTERNS:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Stack: Recent allocations (SP-relative)</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Heap: Pointer chasing, random access</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Arrays: Strided access patterns</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Structures: Clustered field access</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;CONFLICT SCENARIOS:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;1. Instruction fetch vs data access to same cache set</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;2. Sequential instruction stream vs random data access</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;3. Different optimal line sizes (32B vs 64B)</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;4. Different replacement policies needed</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal">};</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal"><span style="font-weight: bold;">// 3. ACTUAL IMPLEMENTATION FOR ALPHA CPU</span></p>
<p class="p_Normal">class AlphaFetchUnit {</p>
<p class="p_Normal">private:</p>
<p class="p_Normal"> &nbsp; &nbsp;UnifiedDataCache* m_instructionCache; &nbsp;// Dedicated L1 I-Cache</p>
<p class="p_Normal"> &nbsp; &nbsp;AlphaCPU* m_cpu;</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;// Optimized instruction fetch with dedicated cache</p>
<p class="p_Normal"> &nbsp; &nbsp;bool fetchInstructionBlock(quint64 pc, quint32* instructions, int count) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Try to fetch entire block from I-Cache</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return m_instructionCache-&gt;read(pc, instructions, count * 4,</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[this](quint64 addr, void* buf, size_t size) -&gt; bool {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// I-Cache miss - fetch from L3 (bypass L2 data cache)</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (m_cpu-&gt;getL3Cache()) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return m_cpu-&gt;getL3Cache()-&gt;read(addr, buf, size,</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[this](quint64 addr2, void* buf2, size_t size2) -&gt; bool {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// L3 miss - fetch from memory</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return m_cpu-&gt;getMemorySystem()-&gt;readVirtualMemory(</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_cpu-&gt;getCpuId(), addr2, buf2, size2, addr2);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Sequential prefetch optimization</p>
<p class="p_Normal"> &nbsp; &nbsp;void prefetchNextBlock(quint64 pc) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 nextBlock = pc + 32; &nbsp;// Prefetch next 32-byte line</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint32 dummy[8];</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Async prefetch - don't stall if miss</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;m_instructionCache-&gt;read(nextBlock, dummy, 32, </p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[](quint64, void*, size_t) { return true; });</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal">};</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">class AlphaExecuteUnit {</p>
<p class="p_Normal">private:</p>
<p class="p_Normal"> &nbsp; &nbsp;UnifiedDataCache* m_dataCache; &nbsp;// Dedicated L2 D-Cache</p>
<p class="p_Normal"> &nbsp; &nbsp;AlphaCPU* m_cpu;</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;// Optimized data access with dedicated cache</p>
<p class="p_Normal"> &nbsp; &nbsp;bool loadData(quint64 vaddr, quint64&amp; value, int size) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Translate address</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 paddr = m_cpu-&gt;translateAddress(vaddr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Access L2 data cache</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return m_dataCache-&gt;read(paddr, &amp;value, size,</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[this](quint64 addr, void* buf, size_t bufSize) -&gt; bool {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// L2 miss - try L3 unified cache</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (m_cpu-&gt;getL3Cache()) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return m_cpu-&gt;getL3Cache()-&gt;read(addr, buf, bufSize,</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[this](quint64 addr2, void* buf2, size_t bufSize2) -&gt; bool {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// L3 miss - fetch from memory</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return m_cpu-&gt;getMemorySystem()-&gt;readVirtualMemory(</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_cpu-&gt;getCpuId(), addr2, buf2, bufSize2, addr2);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;bool storeData(quint64 vaddr, quint64 value, int size) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 paddr = m_cpu-&gt;translateAddress(vaddr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Write to L2 data cache (write-back policy)</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;bool success = m_dataCache-&gt;write(paddr, &amp;value, size,</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[this](quint64 addr, const void* data, size_t dataSize) -&gt; bool {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Write-back to L3</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (m_cpu-&gt;getL3Cache()) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return m_cpu-&gt;getL3Cache()-&gt;write(addr, data, dataSize,</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[this](quint64 addr2, const void* data2, size_t dataSize2) -&gt; bool {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Write-back to memory</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return m_cpu-&gt;getMemorySystem()-&gt;writeVirtualMemory(</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_cpu-&gt;getCpuId(), addr2, data2, dataSize2, addr2);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (success) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Invalidate other CPUs' copies for coherency</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_cpu-&gt;getMemorySystem()-&gt;invalidateCacheLines(paddr, size, m_cpu-&gt;getCpuId());</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return success;</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal">};</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal"><span style="font-weight: bold;">// 4. PERFORMANCE COMPARISON</span></p>
<p class="p_Normal">class CachePerformanceAnalysis {</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;struct PerformanceMetrics {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;double averageInstructionFetchTime;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;double averageDataAccessTime;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;double pipelineUtilization;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int instructionsPerCycle;</p>
<p class="p_Normal"> &nbsp; &nbsp;};</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;PerformanceMetrics analyzeUnifiedL1() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;UNIFIED L1 CACHE (BAD):</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Port conflicts between fetch and execute</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Suboptimal line sizes for both access types</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Thrashing between instruction and data working sets</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Complex arbitration logic</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;Results:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Average fetch time: 2.5 cycles (due to conflicts)</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Average data time: 2.8 cycles (due to conflicts)</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Pipeline utilization: 65%</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- IPC: 2.1</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return {2.5, 2.8, 0.65, 2.1};</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;PerformanceMetrics analyzeSeparateL1L2() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;SEPARATE L1/L2 CACHES (GOOD):</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- No port conflicts</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Optimized for specific access patterns</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Independent working sets</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Parallel access capability</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;Results:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Average fetch time: 1.2 cycles</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Average data time: 1.8 cycles &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Pipeline utilization: 85%</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- IPC: 3.7</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return {1.2, 1.8, 0.85, 3.7};</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;void showPerformanceGains() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;auto unified = analyzeUnifiedL1();</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;auto separate = analyzeSeparateL1L2();</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;double fetchSpeedup = unified.averageInstructionFetchTime / separate.averageInstructionFetchTime;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;double dataSpeedup = unified.averageDataAccessTime / separate.averageDataAccessTime;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;double ipcGain = separate.instructionsPerCycle / unified.instructionsPerCycle;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;PERFORMANCE GAINS FROM SEPARATION:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Instruction fetch: 2.08x faster</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Data access: 1.56x faster</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Overall IPC: 1.76x improvement</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Pipeline efficiency: 31% better utilization</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;WHY L3 UNIFIED WORKS:</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Much larger capacity reduces conflicts</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Higher latency makes port sharing acceptable</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Coherency protocols easier with unified design</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;- Shared working set benefits from unified space</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal">};</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">// 5. SMP COHERENCY BENEFITS</p>
<p class="p_Normal">class SMPCoherencyAnalysis {</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;/*</p>
<p class="p_Normal"> &nbsp; &nbsp;L3 UNIFIED CACHE FOR SMP COHERENCY:</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;ADVANTAGES:</p>
<p class="p_Normal"> &nbsp; &nbsp;1. Single coherency point per CPU</p>
<p class="p_Normal"> &nbsp; &nbsp;2. Directory information co-located with data</p>
<p class="p_Normal"> &nbsp; &nbsp;3. Simplified invalidation protocols</p>
<p class="p_Normal"> &nbsp; &nbsp;4. Reduced inter-CPU traffic</p>
<p class="p_Normal"> &nbsp; &nbsp;5. Inclusive property simplifies coherency</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;COHERENCY PROTOCOL:</p>
<p class="p_Normal"> &nbsp; &nbsp;*/</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;void handleCoherencyEvent(quint64 address, const QString&amp; event, quint16 sourceCpu) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (event == &quot;WRITE&quot;) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 1. Invalidate L1/L2 caches on other CPUs</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;for (auto cpu : m_connectedCpus) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (cpu-&gt;getId() != sourceCpu) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;cpu-&gt;getInstructionCache()-&gt;invalidateLine(address);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;cpu-&gt;getDataCache()-&gt;invalidateLine(address);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// 2. Update directory in L3</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_l3Cache-&gt;updateDirectoryEntry(address, sourceCpu);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal">private:</p>
<p class="p_Normal"> &nbsp; &nbsp;QVector&lt;AlphaCPU*&gt; m_connectedCpus;</p>
<p class="p_Normal"> &nbsp; &nbsp;UnifiedDataCache* m_l3Cache;</p>
<p class="p_Normal">};</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">/*</p>
<p class="p_Normal">SUMMARY OF BENEFITS:</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">1. BANDWIDTH: </p>
<p class="p_Normal"> &nbsp; - Separate I/D caches eliminate port conflicts</p>
<p class="p_Normal"> &nbsp; - Parallel access to instructions and data</p>
<p class="p_Normal"> &nbsp; - Higher sustained pipeline throughput</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">2. OPTIMIZATION:</p>
<p class="p_Normal"> &nbsp; - I-Cache optimized for sequential access patterns</p>
<p class="p_Normal"> &nbsp; - D-Cache optimized for random access patterns &nbsp;</p>
<p class="p_Normal"> &nbsp; - Different line sizes and policies</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">3. WORKING SETS:</p>
<p class="p_Normal"> &nbsp; - Instructions and data don't compete for cache space</p>
<p class="p_Normal"> &nbsp; - Better locality for each access type</p>
<p class="p_Normal"> &nbsp; - Reduced thrashing</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">4. COHERENCY:</p>
<p class="p_Normal"> &nbsp; - L3 provides single coherency point</p>
<p class="p_Normal"> &nbsp; - Simplified invalidation protocols</p>
<p class="p_Normal"> &nbsp; - Reduced inter-CPU communication overhead</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">5. SCALABILITY:</p>
<p class="p_Normal"> &nbsp; - More CPUs can be added without L1/L2 conflicts</p>
<p class="p_Normal"> &nbsp; - L3 shared capacity scales with CPU count</p>
<p class="p_Normal"> &nbsp; - Coherency traffic contained at L3 level</p>
<p class="p_Normal">*/</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">// SPECIFIC CHANGES TO EXISTING UnifiedDataCache.h</p>
<p class="p_Normal">// =================================================</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">// 1. REPLACE SINGLE LOCK WITH FINE-GRAINED LOCKING</p>
<p class="p_Normal">class UnifiedDataCache : public QObject {</p>
<p class="p_Normal"> &nbsp; &nbsp;Q_OBJECT</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">private:</p>
<p class="p_Normal"> &nbsp; &nbsp;// OLD: Single global lock (BLOCKS EVERYTHING)</p>
<p class="p_Normal"> &nbsp; &nbsp;// mutable QReadWriteLock lock; &nbsp;// REMOVE THIS</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// NEW: Fine-grained locking</p>
<p class="p_Normal"> &nbsp; &nbsp;static constexpr int NUM_SETS = 256; &nbsp;// For 256 cache sets</p>
<p class="p_Normal"> &nbsp; &nbsp;mutable QReadWriteLock m_setLocks[NUM_SETS]; &nbsp;// One lock per set</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Banking for parallel access</p>
<p class="p_Normal"> &nbsp; &nbsp;static constexpr int NUM_BANKS = 4;</p>
<p class="p_Normal"> &nbsp; &nbsp;mutable QMutex m_bankMutex[NUM_BANKS];</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Separate data structures for different access types</p>
<p class="p_Normal"> &nbsp; &nbsp;struct CacheSet {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QVector&lt;CacheLine&gt; ways; &nbsp;// Associative ways in this set</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 accessTime; &nbsp; &nbsp; &nbsp; // For LRU replacement</p>
<p class="p_Normal"> &nbsp; &nbsp;};</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;QVector&lt;CacheSet&gt; m_cacheSets[NUM_BANKS]; &nbsp;// Banked cache sets</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;// 2. ADD PORT-SPECIFIC INTERFACES</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Instruction fetch interface (read-only, optimized for sequential access)</p>
<p class="p_Normal"> &nbsp; &nbsp;bool fetchInstruction(quint64 addr, quint32&amp; instruction) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return fetchInstructionBlock(addr, &amp;instruction, 1);</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Optimized instruction block fetch (for superscalar)</p>
<p class="p_Normal"> &nbsp; &nbsp;bool fetchInstructionBlock(quint64 addr, quint32* instructions, int count) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int bank = getBankId(addr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QMutexLocker bankLocker(&amp;m_bankMutex[bank]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;bool allHits = true;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;for (int i = 0; i &lt; count; i++) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;quint64 instAddr = addr + (i * 4);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;int set = getSetIndex(instAddr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Only lock specific set, not entire cache</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;QReadLocker setLocker(&amp;m_setLocks[set]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (!readFromSet(set, instAddr, &amp;instructions[i], 4)) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;allHits = false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Queue background fetch but continue with other instructions</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;queueBackgroundFetch(instAddr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return allHits;</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Data access interface (read/write, optimized for random access)</p>
<p class="p_Normal"> &nbsp; &nbsp;bool loadData(quint64 addr, void* buffer, int size) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int bank = getBankId(addr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int set = getSetIndex(addr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Fine-grained locking - only lock relevant bank and set</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QMutexLocker bankLocker(&amp;m_bankMutex[bank]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QReadLocker setLocker(&amp;m_setLocks[set]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return readFromSet(set, addr, buffer, size);</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;bool storeData(quint64 addr, const void* data, int size) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int bank = getBankId(addr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int set = getSetIndex(addr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Write needs exclusive access to set</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QMutexLocker bankLocker(&amp;m_bankMutex[bank]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QWriteLocker setLocker(&amp;m_setLocks[set]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return writeToSet(set, addr, data, size);</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// 3. ADD PARALLEL ACCESS METHODS</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Parallel instruction fetch + data access</p>
<p class="p_Normal"> &nbsp; &nbsp;struct ParallelAccess {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;bool fetchSuccess;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;bool dataSuccess;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint32 instruction;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 dataValue;</p>
<p class="p_Normal"> &nbsp; &nbsp;};</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;ParallelAccess accessParallel(quint64 fetchAddr, quint64 dataAddr, int dataSize) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;ParallelAccess result = {false, false, 0, 0};</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Use Qt's concurrent framework for true parallelism</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QFuture&lt;bool&gt; fetchFuture = QtConcurrent::run([=, &amp;result]() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return fetchInstruction(fetchAddr, result.instruction);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QFuture&lt;bool&gt; dataFuture = QtConcurrent::run([=, &amp;result]() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return loadData(dataAddr, &amp;result.dataValue, dataSize);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Wait for both operations</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;result.fetchSuccess = fetchFuture.result();</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;result.dataSuccess = dataFuture.result();</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return result;</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// 4. ADD NON-BLOCKING MISS HANDLING</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal">private:</p>
<p class="p_Normal"> &nbsp; &nbsp;// Miss Status Holding Registers for concurrent misses</p>
<p class="p_Normal"> &nbsp; &nbsp;struct MSHR {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 address;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;bool active;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QFuture&lt;bool&gt; fetchOperation;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QVector&lt;std::function&lt;void(bool)&gt;&gt; completionCallbacks;</p>
<p class="p_Normal"> &nbsp; &nbsp;};</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;static constexpr int MAX_MSHRS = 8;</p>
<p class="p_Normal"> &nbsp; &nbsp;MSHR m_mshrs[MAX_MSHRS];</p>
<p class="p_Normal"> &nbsp; &nbsp;QMutex m_mshrMutex;</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;void queueBackgroundFetch(quint64 address) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QMutexLocker locker(&amp;m_mshrMutex);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Check if fetch already in progress</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;for (int i = 0; i &lt; MAX_MSHRS; i++) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (m_mshrs[i].active &amp;&amp; m_mshrs[i].address == (address &amp; LineMask)) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return; &nbsp;// Already fetching this line</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Find free MSHR</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;for (int i = 0; i &lt; MAX_MSHRS; i++) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (!m_mshrs[i].active) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_mshrs[i].address = address &amp; LineMask;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_mshrs[i].active = true;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Start background fetch</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_mshrs[i].fetchOperation = QtConcurrent::run([this, i, address]() {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return performBackgroundFetch(i, address);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;break;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;bool performBackgroundFetch(int mshrIndex, quint64 address) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Fetch from next level or memory</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QByteArray lineData(CacheLineSize, 0);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;bool success = false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (m_nextLevel) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;success = m_nextLevel-&gt;read(address, lineData.data(), CacheLineSize,</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[](quint64, void*, size_t) { return true; });</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (success) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Install in cache</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;installLine(address, lineData);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Complete MSHR</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QMutexLocker locker(&amp;m_mshrMutex);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;m_mshrs[mshrIndex].active = false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return success;</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// 5. BANKING AND SET CALCULATION</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;int getBankId(quint64 addr) const {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Use low-order bits for banking to distribute sequential accesses</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return (addr &gt;&gt; 6) &amp; (NUM_BANKS - 1);</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;int getSetIndex(quint64 addr) const {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Use middle bits for set index</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return (addr &gt;&gt; 6) &amp; (NUM_SETS - 1);</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// 6. SET-SPECIFIC OPERATIONS</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;bool readFromSet(int setIndex, quint64 addr, void* buffer, int size) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Note: Caller must hold appropriate lock for this set</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;CacheSet&amp; set = m_cacheSets[getBankId(addr)][setIndex];</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 tag = getTag(addr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Search ways in this set</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;for (auto&amp; way : set.ways) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (way.valid &amp;&amp; way.tag == tag) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Hit: extract data</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;int offset = addr &amp; (CacheLineSize - 1);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;memcpy(buffer, way.data.constData() + offset, size);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Update LRU</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;set.accessTime = ++m_globalTime;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return true;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return false; &nbsp;// Miss</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;bool writeToSet(int setIndex, quint64 addr, const void* data, int size) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Note: Caller must hold write lock for this set</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;CacheSet&amp; set = m_cacheSets[getBankId(addr)][setIndex];</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;quint64 tag = getTag(addr);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Find or allocate way</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;CacheLine* way = findOrAllocateWay(set, tag);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (!way) return false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Update data</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int offset = addr &amp; (CacheLineSize - 1);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;memcpy(way-&gt;data.data() + offset, data, size);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;way-&gt;dirty = true;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;way-&gt;valid = true;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;way-&gt;tag = tag;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Update LRU</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;set.accessTime = ++m_globalTime;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return true;</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;CacheLine* findOrAllocateWay(CacheSet&amp; set, quint64 tag) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Look for existing way</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;for (auto&amp; way : set.ways) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (way.valid &amp;&amp; way.tag == tag) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return &amp;way;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Look for invalid way</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;for (auto&amp; way : set.ways) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (!way.valid) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return &amp;way;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Need to evict - find LRU way</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Implementation depends on replacement policy</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return &amp;set.ways[0]; &nbsp;// Simplified</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;void installLine(quint64 address, const QByteArray&amp; data) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int bank = getBankId(address);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;int set = getSetIndex(address);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QMutexLocker bankLocker(&amp;m_bankMutex[bank]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QWriteLocker setLocker(&amp;m_setLocks[set]);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;CacheSet&amp; cacheSet = m_cacheSets[bank][set];</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;CacheLine* way = findOrAllocateWay(cacheSet, getTag(address));</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (way) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;way-&gt;data = data;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;way-&gt;valid = true;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;way-&gt;dirty = false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;way-&gt;tag = getTag(address);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal">private:</p>
<p class="p_Normal"> &nbsp; &nbsp;std::atomic&lt;quint64&gt; m_globalTime{0}; &nbsp;// For LRU replacement</p>
<p class="p_Normal">};</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">// 7. UPDATE AlphaCPU TO USE PARALLEL INTERFACES</p>
<p class="p_Normal">&nbsp;</p>
<p class="p_Normal">class AlphaCPU {</p>
<p class="p_Normal">public:</p>
<p class="p_Normal"> &nbsp; &nbsp;// Parallel execution capability</p>
<p class="p_Normal"> &nbsp; &nbsp;bool executeWithParallelCache(quint64 pc, quint64 dataAddr, int dataSize) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Instruction fetch and data access happen in parallel</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;auto result = m_level1InstructionCache-&gt;accessParallel(pc, dataAddr, dataSize);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (!result.fetchSuccess) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Instruction miss - pipeline stall</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;return false;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (!result.dataSuccess &amp;&amp; dataAddr != 0) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Data miss - might be handled by load/store queue</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;queueDataMiss(dataAddr, dataSize);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Decode and execute instruction</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return executeInstruction(result.instruction, result.dataValue);</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp;// Superscalar instruction fetch</p>
<p class="p_Normal"> &nbsp; &nbsp;bool fetchInstructionBlock(quint64 pc, int count) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;QVector&lt;quint32&gt; instructions(count);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;// Fetch multiple instructions in parallel</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;bool success = m_level1InstructionCache-&gt;fetchInstructionBlock(</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;pc, instructions.data(), count);</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;if (success) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// Feed to decode stage</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;for (int i = 0; i &lt; count; i++) {</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;m_decodeQueue.enqueue({pc + i*4, instructions[i]});</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p class="p_Normal"> &nbsp; &nbsp; &nbsp; &nbsp;return success;</p>
<p class="p_Normal"> &nbsp; &nbsp;}</p>
<p class="p_Normal">};</p>

<!--ZOOMSTOP-->
</div></div>
<script type="text/javascript">



function normHeaders() {
 var topicHeadHeight =  $("#idheaderbg > table").first().height() + 1,
	 $topicHeaderBox = $("#idheader"),
	 $topicContentBox = $("#idcontent"),
	 $navHeader = $("#navbar", parent.document),			 
	$navBox = $("div#hmnavframe", parent.document),
	 navHeaderHeight = $navHeader.height();
 if (topicHeadHeight != navHeaderHeight) {
	 $navHeader.css("height",topicHeadHeight + "px");
	 $navBox.css("top", topicHeadHeight + "px");
	 $topicHeaderBox.css("height", topicHeadHeight + "px");
		if ($topicHeaderBox.css("position") == "fixed"){
			$topicContentBox.css("margin-top", topicHeadHeight + "px");
			}
		}
    }
			 
  $(document).ready(function(){
    $(window).on('resize', function() {
      var y = $('#idheader').height(); 
      $('#idcontent').css('margin-top', y);
      var par = window.parent;
      if ($( par ).width() <= $( window ).width()+20) {
        $('#idheader').css('position', 'relative');
        $('#idcontent').css('margin-top', 0);
        $('#idbacktotop').css('display', 'block');
        $('.hmanchor').css('margin-top', -20);
	$('.hmanchor').css('padding-top', 20);
      }
      else {
        $('#idheader').css('position', 'fixed');
        $('#idcontent').css('margin-top', $('#idheader').height());
        $('#idbacktotop').css('display', 'none');
        $('.hmanchor').css('margin-top', -y-20);
		$('.hmanchor').css('padding-top', y+20);
		$("div#hmsplitter", parent.document).css('width', '3px');
      }
	normHeaders();
    });
    
	 $(window).resize(); //trigger event for initially small displays
  });
 

if ((!parent.hmNavigationFrame) && (parent.location) && (parent.location.href)) { $('.sync-toc').show();$('p.crumbs').hide();}

</script>
</body>
</html>
